image_recognition_tensorflow.tf_retrain
=======================================

.. py:module:: image_recognition_tensorflow.tf_retrain

.. autoapi-nested-parse::

   Simple transfer learning with Inception v3 or Mobilenet models.

   With support for TensorBoard.

   This example shows how to take a Inception v3 or Mobilenet model trained on
   ImageNet images, and train a new top layer that can recognize other classes of
   images.

   The top layer receives as input a 2048-dimensional vector (1001-dimensional for
   Mobilenet) for each image. We train a softmax layer on top of this
   representation. Assuming the softmax layer contains N labels, this corresponds
   to learning N + 2048*N (or 1001*N)  model parameters corresponding to the
   learned biases and weights.

   Here's an example, which assumes you have a folder containing class-named
   subfolders, each full of images for each label. The example folder flower_photos
   should have a structure like this:

   ~/flower_photos/daisy/photo1.jpg
   ~/flower_photos/daisy/photo2.jpg
   ...
   ~/flower_photos/rose/anotherphoto77.jpg
   ...
   ~/flower_photos/sunflower/somepicture.jpg

   The subfolder names are important, since they define what label is applied to
   each image, but the filenames themselves don't matter. Once your images are
   prepared, you can run the training with a command like this:


   ```bash
   bazel build tensorflow/examples/image_retraining:retrain && bazel-bin/tensorflow/examples/image_retraining/retrain     --image_dir ~/flower_photos
   ```

   Or, if you have a pip installation of tensorflow, `retrain.py` can be run
   without bazel:

   ```bash
   python tensorflow/examples/image_retraining/retrain.py     --image_dir ~/flower_photos
   ```

   You can replace the image_dir argument with any folder containing subfolders of
   images. The label for each image is taken from the name of the subfolder it's
   in.

   This produces a new model file that can be loaded and run by any TensorFlow
   program, for example the label_image sample code.

   By default this script will use the high accuracy, but comparatively large and
   slow Inception v3 model architecture. It's recommended that you start with this
   to validate that you have gathered good training data, but if you want to deploy
   on resource-limited platforms, you can try the `--architecture` flag with a
   Mobilenet model. For example:

   Run floating-point version of mobilenet:
   ```bash
   python tensorflow/examples/image_retraining/retrain.py     --image_dir ~/flower_photos --architecture mobilenet_1.0_224
   ```

   Run quantized version of mobilenet:
   ```bash
   python tensorflow/examples/image_retraining/retrain.py     --image_dir ~/flower_photos/   --architecture mobilenet_1.0_224_quantized
   ```

   There are 32 different Mobilenet models to choose from, with a variety of file
   size and latency options. The first number can be '1.0', '0.75', '0.50', or
   '0.25' to control the size, and the second controls the input image size, either
   '224', '192', '160', or '128', with smaller sizes running faster. See
   https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html
   for more information on Mobilenet.

   To use with TensorBoard:

   By default, this script will log summaries to /tmp/retrain_logs directory

   Visualize the summaries with this command:

   tensorboard --logdir /tmp/retrain_logs



Attributes
----------

.. autoapisummary::

   image_recognition_tensorflow.tf_retrain.FLAGS
   image_recognition_tensorflow.tf_retrain.MAX_NUM_IMAGES_PER_CLASS
   image_recognition_tensorflow.tf_retrain.bottleneck_path_2_bottleneck_values


Functions
---------

.. autoapisummary::

   image_recognition_tensorflow.tf_retrain.create_image_lists
   image_recognition_tensorflow.tf_retrain.get_image_path
   image_recognition_tensorflow.tf_retrain.get_bottleneck_path
   image_recognition_tensorflow.tf_retrain.create_model_graph
   image_recognition_tensorflow.tf_retrain.run_bottleneck_on_image
   image_recognition_tensorflow.tf_retrain.maybe_download_and_extract
   image_recognition_tensorflow.tf_retrain.ensure_dir_exists
   image_recognition_tensorflow.tf_retrain.create_bottleneck_file
   image_recognition_tensorflow.tf_retrain.get_or_create_bottleneck
   image_recognition_tensorflow.tf_retrain.cache_bottlenecks
   image_recognition_tensorflow.tf_retrain.get_random_cached_bottlenecks
   image_recognition_tensorflow.tf_retrain.get_random_distorted_bottlenecks
   image_recognition_tensorflow.tf_retrain.should_distort_images
   image_recognition_tensorflow.tf_retrain.add_input_distortions
   image_recognition_tensorflow.tf_retrain.variable_summaries
   image_recognition_tensorflow.tf_retrain.add_final_training_ops
   image_recognition_tensorflow.tf_retrain.add_evaluation_step
   image_recognition_tensorflow.tf_retrain.save_graph_to_file
   image_recognition_tensorflow.tf_retrain.prepare_file_system
   image_recognition_tensorflow.tf_retrain.create_model_info
   image_recognition_tensorflow.tf_retrain.add_jpeg_decoding
   image_recognition_tensorflow.tf_retrain.main


Module Contents
---------------

.. py:data:: FLAGS

.. py:data:: MAX_NUM_IMAGES_PER_CLASS
   :value: 134217727


.. py:function:: create_image_lists(image_dir, testing_percentage, validation_percentage)

   Builds a list of training images from the file system.

   Analyzes the sub folders in the image directory, splits them into stable
   training, testing, and validation sets, and returns a data structure
   describing the lists of images for each label and their paths.

   :param image_dir: String path to a folder containing subfolders of images.
   :param testing_percentage: Integer percentage of the images to reserve for tests.
   :param validation_percentage: Integer percentage of images reserved for validation.

   :returns: A dictionary containing an entry for each label subfolder, with images split
             into training, testing, and validation sets within each label.


.. py:function:: get_image_path(image_lists, label_name, index, image_dir, category)

   "Returns a path to an image for a label at the given index.

   :param image_lists: Dictionary of training images for each label.
   :param label_name: Label string we want to get an image for.
   :param index: Int offset of the image we want. This will be moduloed by the
   :param available number of images for the label:
   :param so it can be arbitrarily large.:
   :param image_dir: Root folder string of the subfolders containing the training
   :param images.:
   :param category: Name string of set to pull images from - training, testing, or
   :param validation.:

   :returns: File system path string to an image that meets the requested parameters.


.. py:function:: get_bottleneck_path(image_lists, label_name, index, bottleneck_dir, category, architecture)

   "Returns a path to a bottleneck file for a label at the given index.

   :param image_lists: Dictionary of training images for each label.
   :param label_name: Label string we want to get an image for.
   :param index: Integer offset of the image we want. This will be moduloed by the
   :param available number of images for the label:
   :param so it can be arbitrarily large.:
   :param bottleneck_dir: Folder string holding cached files of bottleneck values.
   :param category: Name string of set to pull images from - training, testing, or
   :param validation.:
   :param architecture: The name of the model architecture.

   :returns: File system path string to an image that meets the requested parameters.


.. py:function:: create_model_graph(model_info)

   "Creates a graph from saved GraphDef file and returns a Graph object.

   :param model_info: Dictionary containing information about the model architecture.

   :returns: Graph holding the trained Inception network, and various tensors we'll be
             manipulating.


.. py:function:: run_bottleneck_on_image(sess, image_data, image_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)

   Runs inference on an image to extract the 'bottleneck' summary layer.

   :param sess: Current active TensorFlow Session.
   :param image_data: String of raw JPEG data.
   :param image_data_tensor: Input data layer in the graph.
   :param decoded_image_tensor: Output of initial image resizing and preprocessing.
   :param resized_input_tensor: The input node of the recognition graph.
   :param bottleneck_tensor: Layer before the final softmax.

   :returns: Numpy array of bottleneck values.


.. py:function:: maybe_download_and_extract(data_url)

   Download and extract model tar file.

   If the pretrained model we're using doesn't already exist, this function
   downloads it from the TensorFlow.org website and unpacks it into a directory.

   :param data_url: Web location of the tar file containing the pretrained model.


.. py:function:: ensure_dir_exists(dir_name)

   Makes sure the folder exists on disk.

   :param dir_name: Path string to the folder we want to create.


.. py:data:: bottleneck_path_2_bottleneck_values

.. py:function:: create_bottleneck_file(bottleneck_path, image_lists, label_name, index, image_dir, category, sess, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor)

   Create a single bottleneck file.


.. py:function:: get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir, category, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)

   Retrieves or calculates bottleneck values for an image.

   If a cached version of the bottleneck data exists on-disk, return that,
   otherwise calculate the data and save it to disk for future use.

   :param sess: The current active TensorFlow Session.
   :param image_lists: Dictionary of training images for each label.
   :param label_name: Label string we want to get an image for.
   :param index: Integer offset of the image we want. This will be modulo-ed by the
   :param available number of images for the label:
   :param so it can be arbitrarily large.:
   :param image_dir: Root folder string of the subfolders containing the training
   :param images.:
   :param category: Name string of which set to pull images from - training, testing,
   :param or validation.:
   :param bottleneck_dir: Folder string holding cached files of bottleneck values.
   :param jpeg_data_tensor: The tensor to feed loaded jpeg data into.
   :param decoded_image_tensor: The output of decoding and resizing the image.
   :param resized_input_tensor: The input node of the recognition graph.
   :param bottleneck_tensor: The output tensor for the bottleneck values.
   :param architecture: The name of the model architecture.

   :returns: Numpy array of values produced by the bottleneck layer for the image.


.. py:function:: cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)

   Ensures all the training, testing, and validation bottlenecks are cached.

   Because we're likely to read the same image multiple times (if there are no
   distortions applied during training) it can speed things up a lot if we
   calculate the bottleneck layer values once for each image during
   preprocessing, and then just read those cached values repeatedly during
   training. Here we go through all the images we've found, calculate those
   values, and save them off.

   :param sess: The current active TensorFlow Session.
   :param image_lists: Dictionary of training images for each label.
   :param image_dir: Root folder string of the subfolders containing the training
   :param images.:
   :param bottleneck_dir: Folder string holding cached files of bottleneck values.
   :param jpeg_data_tensor: Input tensor for jpeg data from file.
   :param decoded_image_tensor: The output of decoding and resizing the image.
   :param resized_input_tensor: The input node of the recognition graph.
   :param bottleneck_tensor: The penultimate output layer of the graph.
   :param architecture: The name of the model architecture.

   :returns: Nothing.


.. py:function:: get_random_cached_bottlenecks(sess, image_lists, how_many, category, bottleneck_dir, image_dir, jpeg_data_tensor, decoded_image_tensor, resized_input_tensor, bottleneck_tensor, architecture)

   Retrieves bottleneck values for cached images.

   If no distortions are being applied, this function can retrieve the cached
   bottleneck values directly from disk for images. It picks a random set of
   images from the specified category.

   :param sess: Current TensorFlow Session.
   :param image_lists: Dictionary of training images for each label.
   :param how_many: If positive, a random sample of this size will be chosen.
   :param If negative:
   :param all bottlenecks will be retrieved.:
   :param category: Name string of which set to pull from - training, testing, or
   :param validation.:
   :param bottleneck_dir: Folder string holding cached files of bottleneck values.
   :param image_dir: Root folder string of the subfolders containing the training
   :param images.:
   :param jpeg_data_tensor: The layer to feed jpeg image data into.
   :param decoded_image_tensor: The output of decoding and resizing the image.
   :param resized_input_tensor: The input node of the recognition graph.
   :param bottleneck_tensor: The bottleneck output layer of the CNN graph.
   :param architecture: The name of the model architecture.

   :returns: List of bottleneck arrays, their corresponding ground truths, and the
             relevant filenames.


.. py:function:: get_random_distorted_bottlenecks(sess, image_lists, how_many, category, image_dir, input_jpeg_tensor, distorted_image, resized_input_tensor, bottleneck_tensor)

   Retrieves bottleneck values for training images, after distortions.

   If we're training with distortions like crops, scales, or flips, we have to
   recalculate the full model for every image, and so we can't use cached
   bottleneck values. Instead we find random images for the requested category,
   run them through the distortion graph, and then the full graph to get the
   bottleneck results for each.

   :param sess: Current TensorFlow Session.
   :param image_lists: Dictionary of training images for each label.
   :param how_many: The integer number of bottleneck values to return.
   :param category: Name string of which set of images to fetch - training, testing,
   :param or validation.:
   :param image_dir: Root folder string of the subfolders containing the training
   :param images.:
   :param input_jpeg_tensor: The input layer we feed the image data to.
   :param distorted_image: The output node of the distortion graph.
   :param resized_input_tensor: The input node of the recognition graph.
   :param bottleneck_tensor: The bottleneck output layer of the CNN graph.

   :returns: List of bottleneck arrays and their corresponding ground truths.


.. py:function:: should_distort_images(flip_left_right, random_crop, random_scale, random_brightness)

   Whether any distortions are enabled, from the input flags.

   :param flip_left_right: Boolean whether to randomly mirror images horizontally.
   :param random_crop: Integer percentage setting the total margin used around the
   :param crop box.:
   :param random_scale: Integer percentage of how much to vary the scale by.
   :param random_brightness: Integer range to randomly multiply the pixel values by.

   :returns: Boolean value indicating whether any distortions should be applied.


.. py:function:: add_input_distortions(flip_left_right, random_crop, random_scale, random_brightness, input_width, input_height, input_depth, input_mean, input_std)

   Creates the operations to apply the specified distortions.

   During training it can help to improve the results if we run the images
   through simple distortions like crops, scales, and flips. These reflect the
   kind of variations we expect in the real world, and so can help train the
   model to cope with natural data more effectively. Here we take the supplied
   parameters and construct a network of operations to apply them to an image.

   Cropping
   ~~~~~~~~

   Cropping is done by placing a bounding box at a random position in the full
   image. The cropping parameter controls the size of that box relative to the
   input image. If it's zero, then the box is the same size as the input and no
   cropping is performed. If the value is 50%, then the crop box will be half the
   width and height of the input. In a diagram it looks like this:

   <       width         >
   +---------------------+
   |                     |
   |   width - crop%     |
   |    <      >         |
   |    +------+         |
   |    |      |         |
   |    |      |         |
   |    |      |         |
   |    +------+         |
   |                     |
   |                     |
   +---------------------+

   Scaling
   ~~~~~~~

   Scaling is a lot like cropping, except that the bounding box is always
   centered and its size varies randomly within the given range. For example if
   the scale percentage is zero, then the bounding box is the same size as the
   input and no scaling is applied. If it's 50%, then the bounding box will be in
   a random range between half the width and height and full size.

   :param flip_left_right: Boolean whether to randomly mirror images horizontally.
   :param random_crop: Integer percentage setting the total margin used around the
   :param crop box.:
   :param random_scale: Integer percentage of how much to vary the scale by.
   :param random_brightness: Integer range to randomly multiply the pixel values by.
   :param graph.:
   :param input_width: Horizontal size of expected input image to model.
   :param input_height: Vertical size of expected input image to model.
   :param input_depth: How many channels the expected input image should have.
   :param input_mean: Pixel value that should be zero in the image for the graph.
   :param input_std: How much to divide the pixel values by before recognition.

   :returns: The jpeg input layer and the distorted result tensor.


.. py:function:: variable_summaries(var)

   Attach a lot of summaries to a Tensor (for TensorBoard visualization).


.. py:function:: add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor, bottleneck_tensor_size, quantize_layer)

   Adds a new softmax and fully-connected layer for training.

   We need to retrain the top layer to identify our new classes, so this function
   adds the right operations to the graph, along with some variables to hold the
   weights, and then sets up all the gradients for the backward pass.

   The set up for the softmax and fully-connected layers is based on:
   https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html

   :param class_count: Integer of how many categories of things we're trying to
                       recognize.
   :param final_tensor_name: Name string for the new final node that produces results.
   :param bottleneck_tensor: The output of the main CNN graph.
   :param bottleneck_tensor_size: How many entries in the bottleneck vector.
   :param quantize_layer: Boolean, specifying whether the newly added layer should be
                          quantized.

   :returns: The tensors for the training and cross entropy results, and tensors for the
             bottleneck input and ground truth input.


.. py:function:: add_evaluation_step(result_tensor, ground_truth_tensor)

   Inserts the operations we need to evaluate the accuracy of our results.

   :param result_tensor: The new final node that produces results.
   :param ground_truth_tensor: The node we feed ground truth data
   :param into.:

   :returns: Tuple of (evaluation step, prediction).


.. py:function:: save_graph_to_file(sess, graph, graph_file_name)

.. py:function:: prepare_file_system()

.. py:function:: create_model_info(architecture)

   Given the name of a model architecture, returns information about it.

   There are different base image recognition pretrained models that can be
   retrained using transfer learning, and this function translates from the name
   of a model to the attributes that are needed to download and train with it.

   :param architecture: Name of a model architecture.

   :returns: Dictionary of information about the model, or None if the name isn't
             recognized

   :raises ValueError: If architecture name is unknown.


.. py:function:: add_jpeg_decoding(input_width, input_height, input_depth, input_mean, input_std)

   Adds operations that perform JPEG decoding and resizing to the graph..

   :param input_width: Desired width of the image fed into the recognizer graph.
   :param input_height: Desired width of the image fed into the recognizer graph.
   :param input_depth: Desired channels of the image fed into the recognizer graph.
   :param input_mean: Pixel value that should be zero in the image for the graph.
   :param input_std: How much to divide the pixel values by before recognition.

   :returns:

             Tensors for the node to feed JPEG data into, and the output of the
               preprocessing steps.


.. py:function:: main(_)

